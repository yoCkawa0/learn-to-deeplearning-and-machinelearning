{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# week4小テスト"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 目次<br>\n",
    "共通問題<br>\n",
    "選択問題<br>\n",
    "・[画像処理](#CNN)<br>\n",
    "・[時系列解析](#RNN)<br>\n",
    "・[自然言語処理](#NLP)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共通問題\n",
    "## Q1 主成分分析・クラスタリング（10点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# 不要な警告を非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コード改変禁止\n",
    "# データをインポート\n",
    "data1 = pd.read_csv(\"./ALL/glass_data.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 全ての変数について標準化を行い、「data_std」という変数に代入してください。その際、データフレームの状態を保ったまま代入してください。その後、各変数の平均値と標準偏差がそれぞれほぼ0と1になっていることを確認してください。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データフレームの状態で標準化を行う(1点)\n",
    "#(値 - 平均) / 標準偏差\n",
    "data_std = \n",
    "# 各変数の平均と標準偏差がそれぞれ0と1になっていることを確認(1点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 1)で標準化を行ったデータに対して、第５主成分まで取得し「X_pca」という変数に代入してください。そして、「X_pca」の初めの５サンプルだけ出力してください。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第5主成分まで取得し代入(1点)\n",
    "\n",
    "# 主成分を初めの5サンプルだけ出力してprint（1点）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 今回モデルでの累積寄与率を表示してください。その後、パレートの法則を元に第何主成分までを用いれば、概ね良いと言えるかを答えてください。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 累積寄与率を出力（1点）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第何主成分まで用いれば良いと考えられるか？（1点）  \n",
    "第**記入**主成分まで用いたほうが良いと考えられる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) エルボー法を用いて、クラスタ数kがk=1～9のときについてのSSEを示したグラフを表示しなさい。そして、グラフをもとに最適なクラスタ数を判断し、Markdown形式で答えてください。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?を変えていきましょう。\n",
    "# 各kで算出されたSSEを格納するリストを定義\n",
    "distortions = []\n",
    "\n",
    "# kを変えながらk-means法を実行（全部できて1点）\n",
    "for k  in range(1,10):              # 1~9クラスタまで繰り返し計算 \n",
    "    km = KMeans(n_clusters=?,       # クラスタの数をk個に指定\n",
    "                init=?,   # セントロイドの初期値をk-means++法で設定\n",
    "                n_init=?,          # セントロイドの初期値を変えての繰り返し回数を10回に指定\n",
    "                max_iter=?,       # 一回の最適化の繰り返し回数を300回に指定\n",
    "                random_state=0)     # 乱数の生成状態を指定（０）\n",
    "    km.fit(X_pca[:, 0:?])           # クラスタリングの計算を実行\n",
    "    distortions.append(km.inertia_) # SSEをリストに格納していく\n",
    "\n",
    "# 結果を散布図に出力\n",
    "plt.plot(range(1,10), distortions,marker='o') # 1から9でのSSEを順にプロット\n",
    "plt.xticks([i for i in range(1, 10)])         # 横軸のメモリを1から9までの1刻みに設定\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最適なクラスタ数は何であると考えられるか？（1点）  \n",
    "最適なクラスタ数は**記入**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) あなたが回答した最適クラスタ数でのクラスタリングを行い、第1主成分,第２主成分を軸とする２次元平面上のサンプル散布図をクラスタリング結果のラベルで色分けしたグラフを表示してください。また、セントロイドも同時に表示してください。（2点）\n",
    "\n",
    "なお、k-means法を実行する際はinit=k-means++で実行してください"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#そのまま実行\n",
    "def kmeans_plot(n_clusters, km, X):\n",
    "    # クラスタの予測値を算出\n",
    "    y_km = km.fit_predict(X)\n",
    "    \n",
    "    # クラスタごとに散布図をプロット\n",
    "    for i, color, marker in zip(range(n_clusters), 'rgbcm', '>o+xv'):\n",
    "        plt.scatter(X[y_km==i, 0],            # 横軸の値\n",
    "                    X[y_km==i, 1],            # 縦軸の値\n",
    "                    color=color,              # プロットの色\n",
    "                    marker=marker,            # プロットの形\n",
    "                    label='cluster ' + str(i) # ラベル\n",
    "                   )\n",
    "    \n",
    "    # クラスタの中心をプロット\n",
    "    plt.scatter(km.cluster_centers_[:, 0],    # 横軸の値\n",
    "                km.cluster_centers_[:, 1],    # 縦軸の値\n",
    "                color='y',                    # プロットの色\n",
    "                marker='*',                   # プロットの形\n",
    "                label='centroids',            # ラベル\n",
    "                s=300,                        # プロットのサイズを大きくして見やすくする\n",
    "               )\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# クラスタリングの結果を出力（全部できて2点）\n",
    "# クラスタごとにサンプルの散布図とクラスタの中心をプロット\n",
    "km = KMeans(n_clusters=?,           # クラスタ数\n",
    "                init=?,   # セントロイドの初期値をk-means++法で設定\n",
    "                n_init=?,          # セントロイドの初期値を変えての繰り返し回数を指定（１０）\n",
    "                max_iter=?,       # 一回の最適化の繰り返し回数を指定（３００）\n",
    "                random_state=0) \n",
    "\n",
    "# 結果の表示\n",
    "kmeans_plot(?, ?, X_pca[:,0:?])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CNN'></a>\n",
    "## 選択問題\n",
    "## Q2 画像処理（20点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "#ライブラリのインポート必ず実行すること\n",
    "#python 3.6 系 keras 2.0.8 を想定している。\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPool2D\n",
    "from keras.optimizers import Adam, Adagrad\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問1 画像データの読み込み （2点）\n",
    "今回はCNNを用いた画像の分類を行う。画像データとして、[CIFAR10](http://www.image-net.org)からダウンロードしたものの一部を使う。  \n",
    "![](http://cdn-ak.f.st-hatena.com/images/fotolife/u/ultraist/20141108/20141108185409.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 画像データ(X_train, X_test, y_train, y_test)をインポートせよ。(2点)\n",
    "\n",
    "data_lightのファイルの中に、X_train,X_test,y_train,y_test.pickleの形で保存されているので、それらを全てインポートすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全て正しくインポートできて2点\n",
    "#下の@@@@@@@@を正しいパスにすること。\n",
    "with open('@@@/x_train.pickle','rb') as f:\n",
    "    X_train = pickle.load(f) \n",
    "\n",
    "with open('@@@/y_train.pickle','rb') as f:\n",
    "    y_train = pickle.load(f) \n",
    "    \n",
    "with open('@@@/x_test.pickle','rb') as f:\n",
    "    X_test = pickle.load(f) \n",
    "    \n",
    "with open('@@@/y_test.pickle','rb') as f:\n",
    "    y_test = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 今回はメモリの都合上35枚の画像データのみを扱う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "X_train = X_train[:35]\n",
    "X_test = X_test[:35]\n",
    "y_train = y_train[:35]\n",
    "y_test = y_test[:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#画像データの確認\n",
    "#コード改変禁止\n",
    "num_classes = 10\n",
    "cifar10_labels = np.array(['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck'])\n",
    "def plot_head(X, y):\n",
    "    plt.figure(figsize=(16,5))\n",
    "    for index in range(30):\n",
    "        plt.subplot(3, 10, index+1)\n",
    "        plt.imshow(X[index])\n",
    "        plt.axis('off')\n",
    "        plt.title(cifar10_labels[y[index][0]])\n",
    "\n",
    "plot_head(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問2 画像データの前処理（7点）\n",
    "このままでは学習に用いることのできる画像データ数が少ないため、水増しを行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) img(画像),x(右上のx座標),y(右上のy座標),px(pixel幅)を引数にとり、(x, y),(x+px, y),(x,y+px),(x+px, y+px)を四隅としてcropした後に、縦32pixel$\\times$横32pixelに拡大した画像を返すcropping関数を定義しなさい。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropping(img, x, y, px):\n",
    "    #(x, y),(x+px, y),(x,y+px),(x+px, y+px)を四隅としてcrop　(1点)\n",
    "    cropped = \n",
    "    #サイズを(32,32)に拡大　(1点)\n",
    "    cropped = \n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 画像を引数にとり、左右反転した画像を返すfrip関数を定義しなさい。（1点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img):\n",
    "    #左右反転　(1点)\n",
    "    flipped = \n",
    "    return flipped    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のcropping関数とflip関数を組み込み、画像を水増しする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "#必ず実行すること\n",
    "def preprocess(X, y):\n",
    "    new_X = np.ndarray((0, 32,32, 3),dtype=np.uint8)\n",
    "    new_y = np.ndarray((0),dtype=int)\n",
    "    for index, img in enumerate(X):\n",
    "        \n",
    "        #crop & flip\n",
    "        for i, j in itertools.product(range(3), range(3)):\n",
    "            cropped = cropping(img, i*4, j*4, 24)\n",
    "            flipped = flip(cropped)\n",
    "        \n",
    "            new_X = np.concatenate([new_X, cropped.reshape(1,32,32,3), flipped.reshape(1,32,32,3)],axis=0)\n",
    "            new_y = np.concatenate([new_y, y[index], y[index]],axis=0)\n",
    "    \n",
    "    #シャッフル\n",
    "    cnt = new_X.shape[0]\n",
    "    \n",
    "    shuffle_array = np.arange(cnt)\n",
    "    np.random.shuffle(shuffle_array)\n",
    "    \n",
    "    new_X = new_X[shuffle_array]\n",
    "    new_y = new_y[shuffle_array]\n",
    "    \n",
    "    new_y = new_y.reshape(-1, 1)\n",
    "            \n",
    "    return new_X, new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) 訓練データにpreprocess関数を適用し、X_train, X_test, y_train, y_testの形状を確かめよ。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数の適用(1点)\n",
    "X_train, y_train = \n",
    "\n",
    "#各データの形状(shape)の確認(1点)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "#以下のコードは改変禁止。関数適用後の画像データについての確認。\n",
    "plot_head(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) X_train, X_testについて、kerasが処理できるfloat型に変換した後に正規化の処理を施せ。（2点）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kerasが処理できる数値型データに変換　(1点)\n",
    "X_train = X_train.astype('f')\n",
    "X_test = X_test.astype('f')\n",
    "# 正規化　（１点）\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "# 正解ラベル(y_trainとy_test)をOne-Hot表現に変換　\n",
    "# 10種類に分類することに注意\n",
    "y_train = np.identity(10)[y_train.reshape(-1)].astype('i')\n",
    "y_test = np.identity(10)[y_test.reshape(-1)].astype('i')\n",
    "\n",
    "print(\"y_train.shape: \",y_train.shape)\n",
    "print(\"y_test.shape: \",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問3 CNNの構築及び学習の実行 （11点）\n",
    "![](https://aistdcontents.blob.core.windows.net/image/deep_image.png)\n",
    "\n",
    "#### <div style=\"text-align: center;\"><font color=\"Red\">※2つの畳み込み層については、paddingを施して画像サイズが変わらないようにしてください。stridesはデフォルトのままで良いです。</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 上の図を参考にしてCNNのmodelを構築せよ。(5点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ※ **DropoutやCNNのpaddingやstrideについての指示もあるので見逃さないこと。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義(計5点)\n",
    "model =\n",
    "\n",
    "## ２次元畳み込み層１ （1点）\n",
    "\n",
    "## ２次元畳み込み層２ （1点）\n",
    "\n",
    "## maxプーリング層 （1点）\n",
    "\n",
    "## 全結合層１ （1点）\n",
    "\n",
    "## 全結合層２ （1点）\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 損失関数を適切に設定し、以下のmodelのコンパイルを完成させよ。 (1点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コンパイルの完成(損失関数の欄を埋める)(1点)\n",
    "model.compile(loss = ? ,\n",
    "              optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) CNNの学習を実行しなさい。ただしbatch_size=35,epochs=12とすること。(1点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) 損失関数のグラフと精度のグラフを描画しなさい。(2点)\n",
    "**ヒント：hist.historyに辞書型配列の形で損失値や精度が格納されている。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; \">ランダムシードの関係で、以下のグラフと全く同じグラフが出力されるという訳ではないことに注意してください。</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 損失関数のグラフ(1点)\n",
    "def plot_history_loss(hist):\n",
    "    \"\"\"\n",
    "    ここに記入\n",
    "    \"\"\"\n",
    "    \n",
    "plot_history_loss(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 精度のグラフ(1点)\n",
    "## hist.historyに辞書型で格納されている。\n",
    "def plot_history_acc(hist):\n",
    "     \"\"\"\n",
    "    ここに記入\n",
    "    \"\"\"\n",
    "    \n",
    "plot_history_acc(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) プロットしたグラフから学習の傾向を分析しなさい。（簡単で構いません。） （1点）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答欄:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (6) 精度を向上するためにどのような工夫が必要か。 （1点）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解答欄: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='RNN'></a>\n",
    "## 選択問題\n",
    "## Q3 時系列処理（20点）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この問題では時系列データの回帰を行います。　<br>\n",
    "５年分の毎日の最低気温のデータをLSTMを用いて学習し予測を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリのインポート\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問1 データの観察(4点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)下記の`url`から`daily-min-temperatures.csv`をカレントディレクトリにダウンロードしてください。(1点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import request\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv'\n",
    "request.urlretrieve(url, './daily-min-temperatures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)`daily-min-temperatures.csv`から初めの5年分のデータを`df`として読み込み、`df`の最初の５つのデータを表示してください。(2点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`daily-min-temperatures.csv`には10年分のデータが含まれていますが、可視化する際にデータが多すぎると分かりにくいため、半分の５年分を用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csvの読み込み\n",
    "df = \n",
    "df = df.iloc[:365*5, :]\n",
    "#最初の５つのデータを表示\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データを可視化すると以下のようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "#データの可視化\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(df.Temp, label='Temp')\n",
    "plt.xticks(np.arange(0, len(df), 120))\n",
    "plt.title('daily-min-temperatures')\n",
    "plt.ylabel('Temperature')\n",
    "plt.legend(loc='best')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)以下の`seasonal_decompose`の結果を見て、`Seasonality(周期変動, 季節性)`からは主に何が読み取れるか説明してください。(1点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#セルの内容は変更せずに実行してください\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "ts = df.Temp\n",
    "decomposition = seasonal_decompose(ts, period=365)\n",
    "\n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal\n",
    "noise = decomposition.resid\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(411)\n",
    "plt.plot(ts, label='Original TS')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(412)\n",
    "plt.plot(trend, label='Trend')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(413)\n",
    "plt.plot(seasonal,label='Seasonality')\n",
    "plt.legend(loc='best')\n",
    "plt.subplot(414)\n",
    "plt.plot(noise, label='Noise')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **解答欄**："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問2 データの前処理 (5点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)df['Temp']の値が0~1になるように正規化してください。(1点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['Temp']の最大値は後で正規化されたデータを元のスケールに復元するために用いるので、scalerという変数に保存しておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#最大値の保存\n",
    "scaler = \n",
    "#正規化\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)以下の画像を参考に入力の系列`X`と正解の系列`y`を1タイムステップずつずれた形で定義してください。(1点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://ai-std-contents.azureedge.net/image/dk6-20.png' width=50%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Xとyの定義(1点)\n",
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)Kerasのモデルの入力に合わせるために、`X`と`y`のshape(次元)を変換してください。(1点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "y = \n",
    "#Xとyのshapeを確認\n",
    "print('X:', np.shape(X), ' y:', np.shape(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)`X`と`y`をtrainデータとtestデータに分割してください。(2点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、はじめの７割のデータ(小数以下切り捨て)をtrainデータとして用いてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_sizeははじめの７割のデータ(小数以下切り捨て)\n",
    "train_size = \n",
    "print(f'train_size : {train_size}')\n",
    "\n",
    "#データの分割\n",
    "X_train = \n",
    "X_test = \n",
    "y_train = \n",
    "y_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#コード改変禁止\n",
    "#データのshapeの確認\n",
    "print('X_train:', X_train.shape)\n",
    "print('X_test :', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test :', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問3 学習と評価(11点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ライブラリのインポート\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, LSTM\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1)30個のLSTMブロックを持つモデルを定義し、損失関数に`mean_squared_error`, 最適化アルゴリズムに`Adam`を用いてコンパイルしてください。(2点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの定義\n",
    "model = \n",
    "\n",
    "\n",
    "#コンパイル\n",
    "#回帰なので損失関数に誤差二乗和を用いる\n",
    "\n",
    "# ミニバッチに含まれるサンプル数を指定\n",
    "batch_size = 32\n",
    "\n",
    "# epoch数を指定\n",
    "n_epoch = 50\n",
    "\n",
    "#モデルの構成の確認\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2)モデルの学習を行ってください。(2点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3)モデルの損失の推移を可視化してください。(2点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hist.history`は辞書型のオブジェクトで`loss`と`val_loss`の推移が記録されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history_loss(hist):\n",
    "    # 損失値(Loss)の遷移のプロット\n",
    "    plt.plot(hist.history['loss'],label=\"loss for training\")\n",
    "    plt.plot(hist.history['val_loss'],label=\"loss for validation\")\n",
    "    plt.title('model loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history_loss(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4)以下の画像を参考にモデルの推測結果を可視化してください。(3点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ただし、モデルの出力は0~1に正規化された値であることに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./RNN/img/pred.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実測値が正しいスケールでプロットされている（1点）\n",
    "#予測値が正しいスケールで正しい日付にプロットされている(1点)\n",
    "# train_sizeがわかるような赤線が引いてある(1点)\n",
    "\n",
    "#元のスケールに復元する\n",
    "\n",
    "\n",
    "#予測データをプロットするための横軸（日数）の数列を作る\n",
    "\n",
    "\n",
    "# プロット\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5)trainデータとtestデータについて、それぞれのRMSEを出力してください。(2点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_rmse = \n",
    "test_rmse = \n",
    "print('train_rmse：',train_rmse)\n",
    "print('test_rmse：',test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='NLP'></a>\n",
    "## 選択問題\n",
    "## Q3 自然言語処理（20点）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 日本の有名な小説４作品を用いて、文章の類似度判定をします。\n",
    "データは青空文庫にあるtxtファイルです。  \n",
    "[青空文庫](https://www.aozora.gr.jp/)は、誰にでもアクセスできる自由な電子本を、図書館のようにインターネット上に集めようとする活動です。  \n",
    "著作権の消滅した作品と、「自由に読んでもらってかまわない」とされたものを、テキストとＸＨＴＭＬ（一部はＨＴＭＬ）形式に電子化した上で揃えています。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "#ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# 不要な警告を非表示にする\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問１データの読み込み(4点)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rashomon_test.txt を、rashomonとして読み込む<br>\n",
    "エンコーディングは、UTF-8 とすること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'rashomon_test.txt'を、rashomonとして読み込み(1点)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torokko_test.txt を、torokko として読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torokko_test.txt を、torokko として読み込む(1点)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gakumonno_susume_test.txt を、gakumonとして読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gakumonno_susume_test.txt を、gakumonとして読み込む(1点)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bocchan_test.txt を、bocchan として読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bocchan_test.txt を、bocchan として読み込む(1点)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'bocchan_test.txt'の中身を確認（画面の邪魔になる場合はコメント化してください）\n",
    "#print(bocchan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問２ データクレンジング(6点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "duty_string = 'C｜o《rai、ebisv》m、pl［ha。fybzk］et。　e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前処理を行う関数`remove_symbol` を下記に定義し、\n",
    "上で定義している`duty_string` の出力結果が`complete` となるようにしなさい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_symbol(text):\n",
    "    '''\n",
    "    input : text\n",
    "    output: 不要な文字を除かれた \"removed\"\n",
    "    '''\n",
    "    # 以下、つづきを記述せよ\n",
    "    \n",
    "    return removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# 正解判定用\n",
    "print(f'前処理後の出力 : {remove_symbol(duty_string)}')\n",
    "print('')\n",
    "print(f'正解判定 : {remove_symbol(duty_string) == \"Complete\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# remove_symbol関数を使用して、４種の文章から不要な文字を削除\n",
    "rashomon = remove_symbol(rashomon)\n",
    "torokko  = remove_symbol(torokko)\n",
    "gakumon  = remove_symbol(gakumon)\n",
    "bocchan  = remove_symbol(bocchan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# 後の解析のために、一つのリストでまとめておく\n",
    "docs = [rashomon, torokko, gakumon, bocchan]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問３トークン化 (5点)\n",
    "\n",
    "形態素解析を行って、トークン化（単語分割、分かち書き、などともいう）をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インストールが済んでいなければコメントアウトを外して実行してください\n",
    "\n",
    "# 形態素解析をし、トークン化するjanomeをインストールする\n",
    "#! pip install janome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### トークン化のための関数を作成せよ(5点)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wakachi(text):\n",
    "    '''\n",
    "    input : text\n",
    "    output: docs (トークン化され、リストに単語ごとに格納された状態)\n",
    "    \n",
    "    '''\n",
    "    # 以下、つづきを記述せよ\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# 正解判定用\n",
    "text = '私は東京都に住んでいます'\n",
    "answer = ['私', 'は', '東京', '都', 'に', '住ん', 'で', 'い', 'ます']\n",
    "\n",
    "print(f'output : {wakachi(text)}')\n",
    "print('')\n",
    "print(f'正解判定 : {wakachi(text)==answer}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# 単語のベクトル化するための関数\n",
    "def vecs_array(documents):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    docs = np.array(documents)\n",
    "    vectorizer = TfidfVectorizer(analyzer=wakachi, binary=True, use_idf=False)\n",
    "    vecs = vectorizer.fit_transform(docs)\n",
    "    return vecs.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cos類似度判定\n",
    "cos類似度判定とは、2つの文章をベクトルとして表したとき、2本のベクトルがどれくらい同じ向きを向いているのかを表す指標です。  \n",
    "完全に同じ向き、同じ大きさの場合に１となります。\n",
    "\n",
    "[詳しくはこちらをご覧ください](https://analysis-navi.com/?p=569%E4%BB%8A%E5%9B%9E%E3%81%AF%E4%BE%8B%E9%A1%8C%E3%81%A8%E3%81%97%E3%81%A6%E3%80%81%E4%BB%A5%E4%B8%8B%E3%81%AE3%E3%81%A4%E3%81%AE%E6%96%87%E7%AB%A0%E3%81%AB%E3%81%A4%E3%81%84%E3%81%A6%E3%80%81%E3%81%9D%E3%82%8C%E3%81%9E%E3%82%8C%E3%81%AE%E9%A1%9E%E4%BC%BC%E5%BA%A6%E3%82%92%E8%A8%88%E7%AE%97%E3%81%97%E3%81%A6%E3%81%BF%E3%81%BE%E3%81%99%E3%80%82%E6%96%87%E7%AB%A0A%E3%80%8C%E7%A7%81%E3%81%AF%E7%8A%AC%E3%81%8C%E5%A5%BD%E3%81%8D%E3%81%A7%E3%81%99%E3%80%82%E3%80%8D%E6%96%87%E7%AB%A0B%E3%80%8C%E7%A7%81%E3%81%AF%E7%8A%AC%E3%81%8C%E5%AB%8C%E3%81%84%E3%81%A7%E3%81%99%E3%80%82%E3%80%8D%E6%96%87%E7%AB%A0C%E3%80%8C%E7%A7%81%E3%81%AF%E7%8A%AC%E3%81%AE%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A8%E3%81%A6%E3%82%82%E5%A5%BD%E3%81%8D%E3%81%A7%E3%81%99%E3%80%82%E3%80%8D%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90%E6%96%87%E7%AB%A0%E3%82%92%E5%8D%98%E8%AA%9E%E3%81%94%E3%81%A8%E3%81%AB%E3%83%90%E3%83%A9%E3%83%90%E3%83%A9%E3%81%AB%E3%81%99%E3%82%8B%E3%80%8C%E5%BD%A2%E6%85%8B%E7%B4%A0%E8%A7%A3%E6%9E%90%E3%80%8D%E3%82%92%E8%A1%8C%E3%81%86%E3%83%91%E3%83%83%E3%82%B1%E3%83%BC%E3%82%B8%E3%81%AFMeCab%E3%80%81Janome%E3%80%81%E3%81%AA%E3%81%A9%E5%B9%BE%E3%81%A4%E3%81%8B%E3%81%82%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改変禁止（実行のみ）\n",
    "\n",
    "# cos類似度の算出\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cs_array = np.round(cosine_similarity(vecs_array(docs), vecs_array(docs)),3)\n",
    "name = ['羅生門', 'トロッコ', '学問のすゝめ', '坊ちゃん']\n",
    "cs_data = pd.DataFrame(cs_array)\n",
    "cs_data.index = name\n",
    "cs_data.columns = name\n",
    "\n",
    "print('cos類似度')\n",
    "cs_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 問3 最も相関のある2作品を答えてください。(5点)\n",
    "ヒント : 相関係数行列のような見方で考えてください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答欄： "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
